{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets,layers,optimizers,Sequential,metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img(imgs,names):\n",
    "  img_new = Image.new('L',(280,280))\n",
    "  index = 0\n",
    "  for i in range(0,280,80):\n",
    "    for j in range(0,280,80):\n",
    "      img = imgs[index]\n",
    "      img = Image.fromarray(img,mode='L')\n",
    "      img_new.paste(img,(i,j))\n",
    "      index+=1\n",
    "  img_new.save(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scale(x):\n",
    "  x = tf.cast(x,dtype=tf.float32)/255.\n",
    "#  y = tf.cast(y,dtype=tf.int32)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dim reduct nums\n",
    "dim_reduce = 10\n",
    "batch_num = 128\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y),(x_test,y_test) = datasets.fashion_mnist.load_data()\n",
    "data = tf.data.Dataset.from_tensor_slices(x)\n",
    "data = data.map(feature_scale).shuffle(10000).batch(128)\n",
    "\n",
    "data_test = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "data_test = data_test.map(feature_scale).batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(keras.Model):\n",
    "  def __init__(self):\n",
    "    super(AE,self).__init__()\n",
    "    #encoder\n",
    "    self.model_encoder = Sequential([layers.Dense(256,activation=tf.nn.relu),\n",
    "                             layers.Dense(128,activation=tf.nn.relu),\n",
    "                             layers.Dense(dim_reduce,activation=tf.nn.relu) ])\n",
    "    #decoder\n",
    "    self.model_decoder = Sequential([layers.Dense(128,activation=tf.nn.relu),\n",
    "                             layers.Dense(256,activation=tf.nn.relu),\n",
    "                             layers.Dense(784,activation=tf.nn.relu)])\n",
    "\n",
    "  def call(self, inputs, training=None):\n",
    "    x = self.model_encoder(inputs)\n",
    "    x = self.model_decoder(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ae\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      (None, 10)                235146    \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 784)               235920    \n",
      "=================================================================\n",
      "Total params: 471,066\n",
      "Trainable params: 471,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = AE()\n",
    "model.build(input_shape=(None,784))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TMU\\anaconda3\\envs\\tf2.6\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 loss: 0.6615171432495117\n",
      "0 100 loss: 0.66971755027771\n",
      "0 200 loss: 0.6667734384536743\n",
      "0 300 loss: 0.6653379797935486\n",
      "0 400 loss: 0.6657999753952026\n",
      "1 0 loss: 0.6649190783500671\n",
      "1 100 loss: 0.6637564301490784\n",
      "1 200 loss: 0.6634138226509094\n",
      "1 300 loss: 0.6610596179962158\n",
      "1 400 loss: 0.6598784923553467\n",
      "2 0 loss: 0.6652801632881165\n",
      "2 100 loss: 0.6691753268241882\n",
      "2 200 loss: 0.6642612218856812\n",
      "2 300 loss: 0.6632861495018005\n",
      "2 400 loss: 0.6679427623748779\n",
      "3 0 loss: 0.6665161848068237\n",
      "3 100 loss: 0.6635338068008423\n",
      "3 200 loss: 0.6644402742385864\n",
      "3 300 loss: 0.6630020141601562\n",
      "3 400 loss: 0.6674457788467407\n",
      "4 0 loss: 0.6629040241241455\n",
      "4 100 loss: 0.6630797386169434\n",
      "4 200 loss: 0.6669543981552124\n",
      "4 300 loss: 0.6623529195785522\n",
      "4 400 loss: 0.6647963523864746\n",
      "5 0 loss: 0.6648557186126709\n",
      "5 100 loss: 0.6655908226966858\n",
      "5 200 loss: 0.6652087569236755\n",
      "5 300 loss: 0.6637266874313354\n",
      "5 400 loss: 0.6631309986114502\n",
      "6 0 loss: 0.6608726978302002\n",
      "6 100 loss: 0.6618208885192871\n",
      "6 200 loss: 0.6649864315986633\n",
      "6 300 loss: 0.6615445613861084\n",
      "6 400 loss: 0.6623821258544922\n",
      "7 0 loss: 0.6612382531166077\n",
      "7 100 loss: 0.6573774814605713\n",
      "7 200 loss: 0.6615335941314697\n",
      "7 300 loss: 0.6642311215400696\n",
      "7 400 loss: 0.6609067320823669\n",
      "8 0 loss: 0.6605812311172485\n",
      "8 100 loss: 0.6585912704467773\n",
      "8 200 loss: 0.659552276134491\n",
      "8 300 loss: 0.6586247086524963\n",
      "8 400 loss: 0.6544786095619202\n",
      "9 0 loss: 0.6573461294174194\n",
      "9 100 loss: 0.6649937033653259\n",
      "9 200 loss: 0.6615511775016785\n",
      "9 300 loss: 0.6569576263427734\n",
      "9 400 loss: 0.6596267223358154\n",
      "10 0 loss: 0.6587054133415222\n",
      "10 100 loss: 0.660530686378479\n",
      "10 200 loss: 0.6565877199172974\n",
      "10 300 loss: 0.6565407514572144\n",
      "10 400 loss: 0.6557159423828125\n",
      "11 0 loss: 0.6589566469192505\n",
      "11 100 loss: 0.6557748317718506\n",
      "11 200 loss: 0.6566688418388367\n",
      "11 300 loss: 0.6589388251304626\n",
      "11 400 loss: 0.6538395285606384\n",
      "12 0 loss: 0.655427098274231\n",
      "12 100 loss: 0.6622308492660522\n",
      "12 200 loss: 0.661651074886322\n",
      "12 300 loss: 0.658602237701416\n",
      "12 400 loss: 0.6581869721412659\n",
      "13 0 loss: 0.656948983669281\n",
      "13 100 loss: 0.6572155952453613\n",
      "13 200 loss: 0.6515060663223267\n",
      "13 300 loss: 0.6559680700302124\n",
      "13 400 loss: 0.661179780960083\n",
      "14 0 loss: 0.6584673523902893\n",
      "14 100 loss: 0.6509802341461182\n",
      "14 200 loss: 0.6590688228607178\n",
      "14 300 loss: 0.6547811627388\n",
      "14 400 loss: 0.6542957425117493\n",
      "15 0 loss: 0.6597791910171509\n",
      "15 100 loss: 0.6554225087165833\n",
      "15 200 loss: 0.6614127159118652\n",
      "15 300 loss: 0.6515271663665771\n",
      "15 400 loss: 0.6591159105300903\n",
      "16 0 loss: 0.658940315246582\n",
      "16 100 loss: 0.6612318754196167\n",
      "16 200 loss: 0.6535882949829102\n",
      "16 300 loss: 0.657840371131897\n",
      "16 400 loss: 0.6542578339576721\n",
      "17 0 loss: 0.6530246734619141\n",
      "17 100 loss: 0.6599841117858887\n",
      "17 200 loss: 0.6585702300071716\n",
      "17 300 loss: 0.6614823341369629\n",
      "17 400 loss: 0.658193826675415\n",
      "18 0 loss: 0.6522736549377441\n",
      "18 100 loss: 0.6517435312271118\n",
      "18 200 loss: 0.6568570733070374\n",
      "18 300 loss: 0.6609898805618286\n",
      "18 400 loss: 0.6611709594726562\n",
      "19 0 loss: 0.6522690653800964\n",
      "19 100 loss: 0.6544901728630066\n",
      "19 200 loss: 0.6530147194862366\n",
      "19 300 loss: 0.6533309817314148\n",
      "19 400 loss: 0.6507978439331055\n"
     ]
    }
   ],
   "source": [
    "optimizer = optimizers.Adam(lr=lr)\n",
    "for i in range(20):\n",
    "  for step,x in enumerate(data):\n",
    "    x = tf.reshape(x,[-1,784])\n",
    "    with tf.GradientTape() as tape:\n",
    "      logits = model(x)\n",
    "      loss = tf.losses.binary_crossentropy(x,logits,from_logits=True)\n",
    "      loss = tf.reduce_mean(loss)\n",
    "    grads = tape.gradient(loss,model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "    \n",
    "    if step %100==0:\n",
    "      print(i,step,'loss:',float(loss))\n",
    "      \n",
    "  x = next(iter(data_test))\n",
    "  val_x = tf.reshape(x,[-1,784])\n",
    "  logits = model(val_x)\n",
    "  x_hat = tf.sigmoid(logits)\n",
    "  x_hat = tf.reshape(x_hat,[-1,28,28])\n",
    "  x_hat = x_hat.numpy()*255\n",
    "  x_hat = x_hat.astype(np.uint8)\n",
    "  if i==19:\n",
    "    save_img(x_hat,'./img_results/AE_img_%d.png'%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(data_test))\n",
    "val_x = tf.reshape(x,[-1,784])\n",
    "logits = model(val_x)\n",
    "x_pred = tf.sigmoid(logits)\n",
    "x_pred = tf.reshape(x_pred,[-1,28,28])\n",
    "x_pred = tf.concat([x,x_pred],axis=0)\n",
    "x_pred = x_pred.numpy()*255\n",
    "x_pred = x_pred.astype(np.uint8)\n",
    "save_img(x_pred,'./img_results/AE_img_total.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
